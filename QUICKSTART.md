# ðŸš€ Nova Agent CLI - Quick Start Guide

## What is Nova?
**Nova** is a complete local AI agent CLI powered by Ollama. It can execute file operations, run shell commands, fetch web contentâ€”all through a beautiful terminal interface with MCP-style tools.

---

## ðŸ“ Project Location
```bash
/Users/chepuriharikiran/Desktop/github/nova-agent-cli/
```

---

## âš¡ Quick Start (Choose One)

### Option 1: Docker (Recommended âœ“)
```bash
cd /Users/chepuriharikiran/Desktop/github/nova-agent-cli

# Start Nova
./scripts/run_docker.sh

# Chat with Nova
docker compose exec nova-agent nova
```

### Option 2: Local Python
```bash
cd /Users/chepuriharikiran/Desktop/github/nova-agent-cli

# Install (one-time)
./scripts/install.sh

# Run Nova
./scripts/run_local.sh
```

> **Note**: Your Python is 3.8.18. Scripts require 3.11+. Docker setup avoids this issue.

---

## ðŸ’¬ Example Commands

### Interactive Chat
```bash
nova

You > Create a file hello.py that prints "Hello World"
You > Now run that file
You > List files in the workspace
You > Fetch https://example.com
```

### One-Shot Mode
```bash
nova -c "What files are in my workspace?"
nova -c "Create a todo list in todos.txt"
nova -m llama3.1:8b  # Use different model
```

---

## ðŸ› ï¸ Available Tools

- **file.read** - Read files from workspace
- **file.write** - Write files to workspace  
- **shell.run** - Execute safe commands (ls, cat, python, git, etc.)
- **web.get** - Fetch content from URLs

All file operations are sandboxed to `workspace/` directory for safety.

---

## ðŸ”§ Configuration

Edit `.env` file:
```bash
OLLAMA_MODEL=llama3              # Change model
OLLAMA_BASE_URL=http://...       # Ollama location
ALLOW_SHELL_COMMANDS=true        # Enable/disable shell
SHELL_COMMAND_ALLOWLIST=ls,cat...  # Add more commands
```

---

## ðŸ³ Docker Commands

```bash
# Start
./scripts/run_docker.sh

# Chat
docker compose exec nova-agent nova

# Stop
docker compose down

# View logs
docker compose logs -f nova-agent

# Rebuild
docker compose up --build
```

---

## ðŸ› Troubleshooting

### Ollama Not Reachable
```bash
# Check Ollama is running
curl http://127.0.0.1:11434/api/tags

# Start Ollama if needed
ollama serve

# Pull model
ollama pull llama3
```

### Docker Can't Reach Ollama
1. Check `.env` has: `OLLAMA_BASE_URL=http://host.docker.internal:11434`
2. Ensure Ollama is running on host

### Python Version (Local Setup)
```bash
# Install Python 3.11+
brew install python@3.11

# Or use Docker (no Python version issues)
```

---

## ðŸ“š Files Overview

```
nova-agent-cli/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ nova_cli.py         # CLI entry point
â”‚   â””â”€â”€ agent_core/
â”‚       â”œâ”€â”€ config.py       # Configuration
â”‚       â”œâ”€â”€ model_client.py # Ollama client
â”‚       â”œâ”€â”€ tools.py        # MCP tools
â”‚       â””â”€â”€ agent_loop.py   # Agent engine
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ install.sh          # Local install
â”‚   â”œâ”€â”€ run_local.sh        # Run locally
â”‚   â””â”€â”€ run_docker.sh       # Run with Docker
â”œâ”€â”€ workspace/              # Your files (sandboxed)
â”œâ”€â”€ docker-compose.yml      # Docker config
â”œâ”€â”€ .env.example           # Config template
â””â”€â”€ README.md              # Full documentation
```

---

## âœ¨ Your Available Models

You already have these models pulled:
- **llama3:latest** (default)
- **llama3.1:8b** (newer, recommended)
- **qwen2:7b-instruct** (fast)
- **deepseek-coder-v2** (coding specialist)
- Plus others!

Switch models:
```bash
nova -m llama3.1:8b
# or edit .env: OLLAMA_MODEL=llama3.1:8b
```

---

## ðŸŽ¯ Try These Examples

1. **File Creation**
   ```
   You > Create a Python script fibonacci.py that generates fibonacci numbers
   ```

2. **Research**
   ```
   You > Fetch the Hacker News homepage and summarize the top stories
   ```

3. **Development**
   ```
   You > Create a package.json for a Node.js project
   You > List all Python files in the workspace
   ```

4. **Multi-Step Tasks**
   ```
   You > Create a README.md, then read it back to me
   ```

---

## ðŸ”’ Safety Features

- âœ“ Workspace sandboxing (file operations only in `workspace/`)
- âœ“ Command allowlisting (only safe commands execute)
- âœ“ Destructive pattern blocking (`rm -rf`, etc. blocked)
- âœ“ Timeout enforcement (30s max)
- âœ“ Local-only (no external API calls except web.get)

---

## ðŸ“– More Information

- **Full docs**: See `README.md` in project directory
- **Implementation details**: See `walkthrough.md` artifact
- **Add new tools**: Edit `src/agent_core/tools.py`

---

**Nova is ready! Start chatting with your local AI agent. ðŸš€**
